{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 4: Analyzing Sentiment\n",
    "\n",
    " * some data: http://help.sentiment140.com/for-students\n",
    "\n",
    "**Columns:**\n",
    "\n",
    "    0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "    1 - the id of the tweet (2087)\n",
    "    2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "    3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "    4 - the user that tweeted (robotickilldozr)\n",
    "    5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the data has already been split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data 1600000\n"
     ]
    }
   ],
   "source": [
    "cols = ['polarity','id', 'date', 'query', 'user', 'tweet']\n",
    "\n",
    "data = pd.read_csv('sentiment.csv',names=cols, encoding='ISO-8859-1')\n",
    "print('length of data {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of data. That's great! However, it will take a long time to get through this notebook with all of that data, so I'm going to randomly choose about 10% of it. We also don't need all of those columns, so let's only keep the ones we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1542165</th>\n",
       "      <td>4</td>\n",
       "      <td>@FatDaddySweets I usually adore your goodies f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023877</th>\n",
       "      <td>4</td>\n",
       "      <td>@trohman That's excellent!! We'd love to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345012</th>\n",
       "      <td>4</td>\n",
       "      <td>Going to go take a shower &amp;amp; get ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336524</th>\n",
       "      <td>4</td>\n",
       "      <td>@jasdeep  but there is a thin strip where ishq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389691</th>\n",
       "      <td>0</td>\n",
       "      <td>It's coming to an end.... Lived, Partied, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505832</th>\n",
       "      <td>0</td>\n",
       "      <td>Some people do not understand that should not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854712</th>\n",
       "      <td>4</td>\n",
       "      <td>@BOHEMiahne shower with a friend or two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510237</th>\n",
       "      <td>4</td>\n",
       "      <td>Mojo...where art thou??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852964</th>\n",
       "      <td>4</td>\n",
       "      <td>@ddlovato don't care bout ppl who r saying u r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547906</th>\n",
       "      <td>4</td>\n",
       "      <td>@bigskyvip Get 100 followers a day using www.t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469242</th>\n",
       "      <td>4</td>\n",
       "      <td>@2012ad Nope.  You got the swine flu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932623</th>\n",
       "      <td>4</td>\n",
       "      <td>@karlalu haha! That's funny. The internet's no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501492</th>\n",
       "      <td>4</td>\n",
       "      <td>Just got to our hotel in Kentucky. Jessica and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410802</th>\n",
       "      <td>0</td>\n",
       "      <td>@jeremielong No new Phone for Vic, Verizon sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211672</th>\n",
       "      <td>4</td>\n",
       "      <td>Weekend was fucking insane actually. A club w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944960</th>\n",
       "      <td>4</td>\n",
       "      <td>@MothmanJim Adrian Peterson wants to &amp;quot;bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239217</th>\n",
       "      <td>4</td>\n",
       "      <td>@CheekiThaSinger if you like 2 laugh..have a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323118</th>\n",
       "      <td>4</td>\n",
       "      <td>@amandabaybee09 just jews!  majority was jews ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275257</th>\n",
       "      <td>0</td>\n",
       "      <td>@checkers so, if they are concluding that ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307648</th>\n",
       "      <td>0</td>\n",
       "      <td>didn't play frisbee...it was raining  but at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168213</th>\n",
       "      <td>4</td>\n",
       "      <td>@charlottexoxo yay u do have pretty nails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809871</th>\n",
       "      <td>4</td>\n",
       "      <td>@perfilip Glad that you enjoyed it brother! it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44309</th>\n",
       "      <td>0</td>\n",
       "      <td>http://twitpic.com/4e1gs - high-five to doggie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241810</th>\n",
       "      <td>0</td>\n",
       "      <td>i'm losing followers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580893</th>\n",
       "      <td>4</td>\n",
       "      <td>am looking forward to going to urban reef in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941048</th>\n",
       "      <td>4</td>\n",
       "      <td>Bloggity Blog  {Spring Senior} | Indiana Senio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338731</th>\n",
       "      <td>4</td>\n",
       "      <td>Why are boys so violent when playing football?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972645</th>\n",
       "      <td>4</td>\n",
       "      <td>btw- Desiree's friend -loved your blog on dinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15370</th>\n",
       "      <td>0</td>\n",
       "      <td>ugh i guess i should start reading the 100 pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160921</th>\n",
       "      <td>4</td>\n",
       "      <td>@ROCKGUITARZ: What kind of underwater &amp;quot;th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050352</th>\n",
       "      <td>4</td>\n",
       "      <td>Guess who's pretty much moving back to kennesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049807</th>\n",
       "      <td>4</td>\n",
       "      <td>@Domulka WOOOOOOOOOOOOOOOOOOOW DDD that's frea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355399</th>\n",
       "      <td>4</td>\n",
       "      <td>@Valv30  heyyy! you hiding from me?! you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376410</th>\n",
       "      <td>4</td>\n",
       "      <td>@Pinkis4gangstas I'm pretty sure they are amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517054</th>\n",
       "      <td>0</td>\n",
       "      <td>@donnbh Have funnnnn!!! I did SWAT workout tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385259</th>\n",
       "      <td>0</td>\n",
       "      <td>The reflection in the mirror aint the same any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964957</th>\n",
       "      <td>4</td>\n",
       "      <td>sittin' on the curb out sidda work. enjoyin' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049884</th>\n",
       "      <td>4</td>\n",
       "      <td>@RachieRach3 don't think about Oreos. Think ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898556</th>\n",
       "      <td>4</td>\n",
       "      <td>Had a great idea for an OS. Not sharing it tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174194</th>\n",
       "      <td>0</td>\n",
       "      <td>@RussellMoyer ahaha i know. but now i can't do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191704</th>\n",
       "      <td>0</td>\n",
       "      <td>@benshephard I agree terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688751</th>\n",
       "      <td>0</td>\n",
       "      <td>@annemjw oh sweetie.  at least it's over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666338</th>\n",
       "      <td>0</td>\n",
       "      <td>@c0rtex the problem my friend is there are fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356420</th>\n",
       "      <td>0</td>\n",
       "      <td>Giving 9 cats a bath made my house sound like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007250</th>\n",
       "      <td>4</td>\n",
       "      <td>@RealHughJackman I've met Tatiana Chudnovskaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261675</th>\n",
       "      <td>0</td>\n",
       "      <td>@VarrenAKABabyV awww that sucks, hun.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562834</th>\n",
       "      <td>0</td>\n",
       "      <td>@dawnd66 I had none!!! I'm surrounded by sick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596688</th>\n",
       "      <td>0</td>\n",
       "      <td>is realllllyyy sleepy! ... still 4 hours to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282761</th>\n",
       "      <td>4</td>\n",
       "      <td>@GinJam you're just like Michael Palin you are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969762</th>\n",
       "      <td>4</td>\n",
       "      <td>lollz 12 friends online. im so popular. everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360423</th>\n",
       "      <td>4</td>\n",
       "      <td>no one's happy. :/ there's so many people out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458177</th>\n",
       "      <td>4</td>\n",
       "      <td>bought new shoes in freo today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909261</th>\n",
       "      <td>4</td>\n",
       "      <td>Almost dun choreographing the dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915762</th>\n",
       "      <td>4</td>\n",
       "      <td>watching snl with my ucsd girls and laughing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14687</th>\n",
       "      <td>0</td>\n",
       "      <td>I would say this shoe shopping trip was a fail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030099</th>\n",
       "      <td>4</td>\n",
       "      <td>love, love, LOVE green day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283614</th>\n",
       "      <td>4</td>\n",
       "      <td>Just working today in finishing 2 new tracks  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218582</th>\n",
       "      <td>0</td>\n",
       "      <td>At Great Wall China Buffet in pickering. So fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79877</th>\n",
       "      <td>0</td>\n",
       "      <td>missing everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186534</th>\n",
       "      <td>4</td>\n",
       "      <td>@AshleySpencer86 Thank you so much!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity                                              tweet\n",
       "1542165         4  @FatDaddySweets I usually adore your goodies f...\n",
       "1023877         4  @trohman That's excellent!! We'd love to have ...\n",
       "1345012         4         Going to go take a shower &amp; get ready \n",
       "1336524         4  @jasdeep  but there is a thin strip where ishq...\n",
       "389691          0  It's coming to an end.... Lived, Partied, and ...\n",
       "505832          0  Some people do not understand that should not ...\n",
       "854712          4           @BOHEMiahne shower with a friend or two \n",
       "1510237         4                           Mojo...where art thou?? \n",
       "852964          4  @ddlovato don't care bout ppl who r saying u r...\n",
       "1547906         4  @bigskyvip Get 100 followers a day using www.t...\n",
       "1469242         4            @2012ad Nope.  You got the swine flu.  \n",
       "932623          4  @karlalu haha! That's funny. The internet's no...\n",
       "1501492         4  Just got to our hotel in Kentucky. Jessica and...\n",
       "410802          0  @jeremielong No new Phone for Vic, Verizon sai...\n",
       "1211672         4  Weekend was fucking insane actually. A club w/...\n",
       "944960          4  @MothmanJim Adrian Peterson wants to &quot;bul...\n",
       "1239217         4  @CheekiThaSinger if you like 2 laugh..have a g...\n",
       "1323118         4  @amandabaybee09 just jews!  majority was jews ...\n",
       "275257          0  @checkers so, if they are concluding that ther...\n",
       "307648          0  didn't play frisbee...it was raining  but at l...\n",
       "1168213         4         @charlottexoxo yay u do have pretty nails \n",
       "809871          4  @perfilip Glad that you enjoyed it brother! it...\n",
       "44309           0  http://twitpic.com/4e1gs - high-five to doggie...\n",
       "241810          0                              i'm losing followers \n",
       "1580893         4  am looking forward to going to urban reef in b...\n",
       "941048          4  Bloggity Blog  {Spring Senior} | Indiana Senio...\n",
       "1338731         4  Why are boys so violent when playing football?...\n",
       "972645          4  btw- Desiree's friend -loved your blog on dinn...\n",
       "15370           0  ugh i guess i should start reading the 100 pag...\n",
       "1160921         4  @ROCKGUITARZ: What kind of underwater &quot;th...\n",
       "...           ...                                                ...\n",
       "1050352         4  Guess who's pretty much moving back to kennesa...\n",
       "1049807         4  @Domulka WOOOOOOOOOOOOOOOOOOOW DDD that's frea...\n",
       "1355399         4  @Valv30  heyyy! you hiding from me?! you know ...\n",
       "1376410         4  @Pinkis4gangstas I'm pretty sure they are amaz...\n",
       "517054          0  @donnbh Have funnnnn!!! I did SWAT workout tod...\n",
       "385259          0  The reflection in the mirror aint the same any...\n",
       "964957          4  sittin' on the curb out sidda work. enjoyin' a...\n",
       "1049884         4  @RachieRach3 don't think about Oreos. Think ab...\n",
       "898556          4  Had a great idea for an OS. Not sharing it tho...\n",
       "174194          0  @RussellMoyer ahaha i know. but now i can't do...\n",
       "191704          0                     @benshephard I agree terrible \n",
       "688751          0          @annemjw oh sweetie.  at least it's over.\n",
       "666338          0  @c0rtex the problem my friend is there are fri...\n",
       "356420          0  Giving 9 cats a bath made my house sound like ...\n",
       "1007250         4  @RealHughJackman I've met Tatiana Chudnovskaya...\n",
       "261675          0             @VarrenAKABabyV awww that sucks, hun. \n",
       "562834          0  @dawnd66 I had none!!! I'm surrounded by sick ...\n",
       "596688          0    is realllllyyy sleepy! ... still 4 hours to go \n",
       "1282761         4  @GinJam you're just like Michael Palin you are...\n",
       "969762          4  lollz 12 friends online. im so popular. everyo...\n",
       "1360423         4  no one's happy. :/ there's so many people out ...\n",
       "1458177         4                    bought new shoes in freo today \n",
       "909261          4               Almost dun choreographing the dance \n",
       "915762          4  watching snl with my ucsd girls and laughing a...\n",
       "14687           0  I would say this shoe shopping trip was a fail...\n",
       "1030099         4                        love, love, LOVE green day \n",
       "1283614         4  Just working today in finishing 2 new tracks  ...\n",
       "218582          0  At Great Wall China Buffet in pickering. So fu...\n",
       "79877           0                                  missing everyone \n",
       "1186534         4               @AshleySpencer86 Thank you so much! \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.sample(frac=0.005,random_state=200)\n",
    "data = data.drop(['id', 'date', 'query', 'user'], axis=1)\n",
    "#data[:3]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of each type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) How many of each polarity are there?\n",
    "\n",
    "* Hint: use a mask over the `data` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4014 entries with polarity 0\n",
      "There are 3986 entries with polarity 4\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(data[data.polarity == 0])) + ' entries with polarity 0')\n",
    "print('There are ' + str(len(data[data.polarity == 4])) + ' entries with polarity 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Change all 4s in polarity to 1\n",
    "\n",
    "* Hint: a lambda function might be useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['polarity'] = data['polarity'].map(lambda x: 1 if x == 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1542165</th>\n",
       "      <td>1</td>\n",
       "      <td>@FatDaddySweets I usually adore your goodies f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023877</th>\n",
       "      <td>1</td>\n",
       "      <td>@trohman That's excellent!! We'd love to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345012</th>\n",
       "      <td>1</td>\n",
       "      <td>Going to go take a shower &amp;amp; get ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336524</th>\n",
       "      <td>1</td>\n",
       "      <td>@jasdeep  but there is a thin strip where ishq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389691</th>\n",
       "      <td>0</td>\n",
       "      <td>It's coming to an end.... Lived, Partied, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505832</th>\n",
       "      <td>0</td>\n",
       "      <td>Some people do not understand that should not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854712</th>\n",
       "      <td>1</td>\n",
       "      <td>@BOHEMiahne shower with a friend or two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510237</th>\n",
       "      <td>1</td>\n",
       "      <td>Mojo...where art thou??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852964</th>\n",
       "      <td>1</td>\n",
       "      <td>@ddlovato don't care bout ppl who r saying u r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547906</th>\n",
       "      <td>1</td>\n",
       "      <td>@bigskyvip Get 100 followers a day using www.t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469242</th>\n",
       "      <td>1</td>\n",
       "      <td>@2012ad Nope.  You got the swine flu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932623</th>\n",
       "      <td>1</td>\n",
       "      <td>@karlalu haha! That's funny. The internet's no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501492</th>\n",
       "      <td>1</td>\n",
       "      <td>Just got to our hotel in Kentucky. Jessica and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410802</th>\n",
       "      <td>0</td>\n",
       "      <td>@jeremielong No new Phone for Vic, Verizon sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211672</th>\n",
       "      <td>1</td>\n",
       "      <td>Weekend was fucking insane actually. A club w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944960</th>\n",
       "      <td>1</td>\n",
       "      <td>@MothmanJim Adrian Peterson wants to &amp;quot;bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239217</th>\n",
       "      <td>1</td>\n",
       "      <td>@CheekiThaSinger if you like 2 laugh..have a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323118</th>\n",
       "      <td>1</td>\n",
       "      <td>@amandabaybee09 just jews!  majority was jews ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275257</th>\n",
       "      <td>0</td>\n",
       "      <td>@checkers so, if they are concluding that ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307648</th>\n",
       "      <td>0</td>\n",
       "      <td>didn't play frisbee...it was raining  but at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168213</th>\n",
       "      <td>1</td>\n",
       "      <td>@charlottexoxo yay u do have pretty nails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809871</th>\n",
       "      <td>1</td>\n",
       "      <td>@perfilip Glad that you enjoyed it brother! it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44309</th>\n",
       "      <td>0</td>\n",
       "      <td>http://twitpic.com/4e1gs - high-five to doggie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241810</th>\n",
       "      <td>0</td>\n",
       "      <td>i'm losing followers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580893</th>\n",
       "      <td>1</td>\n",
       "      <td>am looking forward to going to urban reef in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941048</th>\n",
       "      <td>1</td>\n",
       "      <td>Bloggity Blog  {Spring Senior} | Indiana Senio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338731</th>\n",
       "      <td>1</td>\n",
       "      <td>Why are boys so violent when playing football?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972645</th>\n",
       "      <td>1</td>\n",
       "      <td>btw- Desiree's friend -loved your blog on dinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15370</th>\n",
       "      <td>0</td>\n",
       "      <td>ugh i guess i should start reading the 100 pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160921</th>\n",
       "      <td>1</td>\n",
       "      <td>@ROCKGUITARZ: What kind of underwater &amp;quot;th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050352</th>\n",
       "      <td>1</td>\n",
       "      <td>Guess who's pretty much moving back to kennesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049807</th>\n",
       "      <td>1</td>\n",
       "      <td>@Domulka WOOOOOOOOOOOOOOOOOOOW DDD that's frea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355399</th>\n",
       "      <td>1</td>\n",
       "      <td>@Valv30  heyyy! you hiding from me?! you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376410</th>\n",
       "      <td>1</td>\n",
       "      <td>@Pinkis4gangstas I'm pretty sure they are amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517054</th>\n",
       "      <td>0</td>\n",
       "      <td>@donnbh Have funnnnn!!! I did SWAT workout tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385259</th>\n",
       "      <td>0</td>\n",
       "      <td>The reflection in the mirror aint the same any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964957</th>\n",
       "      <td>1</td>\n",
       "      <td>sittin' on the curb out sidda work. enjoyin' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049884</th>\n",
       "      <td>1</td>\n",
       "      <td>@RachieRach3 don't think about Oreos. Think ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898556</th>\n",
       "      <td>1</td>\n",
       "      <td>Had a great idea for an OS. Not sharing it tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174194</th>\n",
       "      <td>0</td>\n",
       "      <td>@RussellMoyer ahaha i know. but now i can't do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191704</th>\n",
       "      <td>0</td>\n",
       "      <td>@benshephard I agree terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688751</th>\n",
       "      <td>0</td>\n",
       "      <td>@annemjw oh sweetie.  at least it's over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666338</th>\n",
       "      <td>0</td>\n",
       "      <td>@c0rtex the problem my friend is there are fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356420</th>\n",
       "      <td>0</td>\n",
       "      <td>Giving 9 cats a bath made my house sound like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007250</th>\n",
       "      <td>1</td>\n",
       "      <td>@RealHughJackman I've met Tatiana Chudnovskaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261675</th>\n",
       "      <td>0</td>\n",
       "      <td>@VarrenAKABabyV awww that sucks, hun.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562834</th>\n",
       "      <td>0</td>\n",
       "      <td>@dawnd66 I had none!!! I'm surrounded by sick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596688</th>\n",
       "      <td>0</td>\n",
       "      <td>is realllllyyy sleepy! ... still 4 hours to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282761</th>\n",
       "      <td>1</td>\n",
       "      <td>@GinJam you're just like Michael Palin you are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969762</th>\n",
       "      <td>1</td>\n",
       "      <td>lollz 12 friends online. im so popular. everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360423</th>\n",
       "      <td>1</td>\n",
       "      <td>no one's happy. :/ there's so many people out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458177</th>\n",
       "      <td>1</td>\n",
       "      <td>bought new shoes in freo today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909261</th>\n",
       "      <td>1</td>\n",
       "      <td>Almost dun choreographing the dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915762</th>\n",
       "      <td>1</td>\n",
       "      <td>watching snl with my ucsd girls and laughing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14687</th>\n",
       "      <td>0</td>\n",
       "      <td>I would say this shoe shopping trip was a fail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030099</th>\n",
       "      <td>1</td>\n",
       "      <td>love, love, LOVE green day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283614</th>\n",
       "      <td>1</td>\n",
       "      <td>Just working today in finishing 2 new tracks  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218582</th>\n",
       "      <td>0</td>\n",
       "      <td>At Great Wall China Buffet in pickering. So fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79877</th>\n",
       "      <td>0</td>\n",
       "      <td>missing everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186534</th>\n",
       "      <td>1</td>\n",
       "      <td>@AshleySpencer86 Thank you so much!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity                                              tweet\n",
       "1542165         1  @FatDaddySweets I usually adore your goodies f...\n",
       "1023877         1  @trohman That's excellent!! We'd love to have ...\n",
       "1345012         1         Going to go take a shower &amp; get ready \n",
       "1336524         1  @jasdeep  but there is a thin strip where ishq...\n",
       "389691          0  It's coming to an end.... Lived, Partied, and ...\n",
       "505832          0  Some people do not understand that should not ...\n",
       "854712          1           @BOHEMiahne shower with a friend or two \n",
       "1510237         1                           Mojo...where art thou?? \n",
       "852964          1  @ddlovato don't care bout ppl who r saying u r...\n",
       "1547906         1  @bigskyvip Get 100 followers a day using www.t...\n",
       "1469242         1            @2012ad Nope.  You got the swine flu.  \n",
       "932623          1  @karlalu haha! That's funny. The internet's no...\n",
       "1501492         1  Just got to our hotel in Kentucky. Jessica and...\n",
       "410802          0  @jeremielong No new Phone for Vic, Verizon sai...\n",
       "1211672         1  Weekend was fucking insane actually. A club w/...\n",
       "944960          1  @MothmanJim Adrian Peterson wants to &quot;bul...\n",
       "1239217         1  @CheekiThaSinger if you like 2 laugh..have a g...\n",
       "1323118         1  @amandabaybee09 just jews!  majority was jews ...\n",
       "275257          0  @checkers so, if they are concluding that ther...\n",
       "307648          0  didn't play frisbee...it was raining  but at l...\n",
       "1168213         1         @charlottexoxo yay u do have pretty nails \n",
       "809871          1  @perfilip Glad that you enjoyed it brother! it...\n",
       "44309           0  http://twitpic.com/4e1gs - high-five to doggie...\n",
       "241810          0                              i'm losing followers \n",
       "1580893         1  am looking forward to going to urban reef in b...\n",
       "941048          1  Bloggity Blog  {Spring Senior} | Indiana Senio...\n",
       "1338731         1  Why are boys so violent when playing football?...\n",
       "972645          1  btw- Desiree's friend -loved your blog on dinn...\n",
       "15370           0  ugh i guess i should start reading the 100 pag...\n",
       "1160921         1  @ROCKGUITARZ: What kind of underwater &quot;th...\n",
       "...           ...                                                ...\n",
       "1050352         1  Guess who's pretty much moving back to kennesa...\n",
       "1049807         1  @Domulka WOOOOOOOOOOOOOOOOOOOW DDD that's frea...\n",
       "1355399         1  @Valv30  heyyy! you hiding from me?! you know ...\n",
       "1376410         1  @Pinkis4gangstas I'm pretty sure they are amaz...\n",
       "517054          0  @donnbh Have funnnnn!!! I did SWAT workout tod...\n",
       "385259          0  The reflection in the mirror aint the same any...\n",
       "964957          1  sittin' on the curb out sidda work. enjoyin' a...\n",
       "1049884         1  @RachieRach3 don't think about Oreos. Think ab...\n",
       "898556          1  Had a great idea for an OS. Not sharing it tho...\n",
       "174194          0  @RussellMoyer ahaha i know. but now i can't do...\n",
       "191704          0                     @benshephard I agree terrible \n",
       "688751          0          @annemjw oh sweetie.  at least it's over.\n",
       "666338          0  @c0rtex the problem my friend is there are fri...\n",
       "356420          0  Giving 9 cats a bath made my house sound like ...\n",
       "1007250         1  @RealHughJackman I've met Tatiana Chudnovskaya...\n",
       "261675          0             @VarrenAKABabyV awww that sucks, hun. \n",
       "562834          0  @dawnd66 I had none!!! I'm surrounded by sick ...\n",
       "596688          0    is realllllyyy sleepy! ... still 4 hours to go \n",
       "1282761         1  @GinJam you're just like Michael Palin you are...\n",
       "969762          1  lollz 12 friends online. im so popular. everyo...\n",
       "1360423         1  no one's happy. :/ there's so many people out ...\n",
       "1458177         1                    bought new shoes in freo today \n",
       "909261          1               Almost dun choreographing the dance \n",
       "915762          1  watching snl with my ucsd girls and laughing a...\n",
       "14687           0  I would say this shoe shopping trip was a fail...\n",
       "1030099         1                        love, love, LOVE green day \n",
       "1283614         1  Just working today in finishing 2 new tracks  ...\n",
       "218582          0  At Great Wall China Buffet in pickering. So fu...\n",
       "79877           0                                  missing everyone \n",
       "1186534         1               @AshleySpencer86 Thank you so much! \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[:3]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) split the data into 10% test, 10% and 80% train\n",
    "\n",
    "* create `test`, `dev`, and `train` data tables\n",
    "* you can use the `.sample()` method for the dataframe\n",
    "* print out the shapes of each of the three tables\n",
    "* What is the baseline for this task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 2), (800, 2), (800, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from sklearn import model_selection as ms\n",
    "\n",
    "# Shuffle the data so that each of our slices have some of each label\n",
    "# Stratify based on class labels\n",
    "# sklearn has functions for this, but only for splitting between train and test,\n",
    "# so we hack that a bit to split between train and test/dev, then between test and\n",
    "# dev\n",
    "sss = ms.StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 1234)\n",
    "train = None\n",
    "dev_test = None\n",
    "dev = None\n",
    "test = None\n",
    "for train_idx, dev_test_idx in sss.split(data.tweet, data.polarity):\n",
    "    train = data.iloc[train_idx]\n",
    "    dev_test = data.iloc[dev_test_idx]\n",
    "sss = ms.StratifiedShuffleSplit(n_splits = 1, test_size = 0.5, random_state = 1234)\n",
    "for dev_idx, test_idx in sss.split(dev_test.tweet, dev_test.polarity):\n",
    "    dev = dev_test.iloc[dev_idx]\n",
    "    test = dev_test.iloc[test_idx]\n",
    "# drop dev_test from memory. I'm running into memory issues.\n",
    "dev_test = None\n",
    "# Expected output: ((128029, 2), (16004, 2), (16004, 2))\n",
    "train.shape, dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Use a LabelEncoder to convert the tweet column to numbers\n",
    "\n",
    "* I do this for you. Just run the following cells to see how well representing a full tweet as an index number works for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.polarity.as_matrix()\n",
    "\n",
    "# Expected (128029,)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "leX = preprocessing.LabelEncoder()\n",
    "leX.fit(data.tweet) # use the original data df so all possibilities are encoded\n",
    "X = leX.transform(train.tweet)\n",
    "X = X.reshape(X.shape[0], 1)\n",
    "\n",
    "# Expected (128029, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l2')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdev = leX.transform(dev.tweet)\n",
    "Xdev = Xdev.reshape(Xdev.shape[0], 1)\n",
    "ydev = dev.polarity.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "# Expected 0.49725068732816796\n",
    "accuracy_score(model.predict(Xdev), ydev) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Anaylsis of LabelEncoder\n",
    "\n",
    "* How well does LabelEncoder perform compared to the baseline?\n",
    "* Why does it perform so poorly? What does it have to do with the way the features are represented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoder doesn't make any connection between different sentences. For example, the sentences, s_1 = \"I had a burger at McDonalds\" and s_2 = \"My favorite burger place is Five Guys\" would have completely different label values, despite them both talking about food in general and burgers in particular. Encoding sentences in one dimension is difficult, because you lose any semantic meaning between the various words in the sentence, and thus the connections between the sentences as well.\n",
    "\n",
    "In addition, a label encoder imposes an arbitrary order on the sentences. If the sentence s_3 = \"I like cats\" happens to be encoded as 3, the sentence \"I had a burger at McDonalds\" happens to be encoded as 4, and the sentence \"My favorite burger place is Five Guys\" happens to be encoded as 9999, then s_1 would be interpreted by the model as semantically closer to s_3 than s_2, even though intuitively, s_1 and s_2 should be closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.) one-hot encoding\n",
    "\n",
    "* Repeat the steps of preparing the test and dev data as in #4, only this time use one-hot vectors instead of the label encoder\n",
    "* Hint: do you want to represent the entire tweet as a vector, or each word? (Hint: use words to make the one-hot encoder, then sum them to represent the entire tweet)\n",
    "* Hint: try `get_dummies()`, alternatively use scikitlearn's OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy for sparse matrices\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "# Drop data to save memory\n",
    "data = None\n",
    "\n",
    "# Transform the data by splitting on word\n",
    "X_tr = train.tweet.map(lambda x: x.split()).as_matrix()\n",
    "X_dev = dev.tweet.map(lambda x: x.split()).as_matrix()\n",
    "\n",
    "y_tr = train.polarity.as_matrix()\n",
    "y_dev = dev.polarity.as_matrix()\n",
    "\n",
    "# I couldn't figure out how to get get_dummies or sklearn's OneHotEncoder\n",
    "# to work with the words in the sentences instead of just the sentences.\n",
    "# The one hot was just taking each sentence value and making a new column\n",
    "# for each sentence instead of a column for each word, so I ended up kinda\n",
    "# implementing my own sentence word one-hot encoder.\n",
    "\n",
    "# Pass in a list of lists. The outer list is the rows of our training data,\n",
    "# the inner lists are the words. Returns a list encoding indexes to words.\n",
    "def one_hot_sentence_word_fit(X):\n",
    "    result = set()\n",
    "    for X_cur in X:\n",
    "        for word_cur in X_cur:\n",
    "            result.add(word_cur)\n",
    "    # Convert result into a list to map index (column in the new matrix) to word.\n",
    "    return list(result)\n",
    "\n",
    "# X is the data to fit, model is the list of words seen in our training data.\n",
    "# Encode the sentences as one-hot on each word. Words not in the model will be completely\n",
    "# ignored in this approach. A second approach could be to have a wildcard entry in the table to hold\n",
    "# words we've never seen before.\n",
    "def one_hot_sentence_word_transform(X, model):\n",
    "    # Was using csr, but I got a warning that lil would be better\n",
    "    result = sp.sparse.lil_matrix((X.shape[0], len(model)))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(len(model)):\n",
    "            word = model[j]\n",
    "            num_appearances = X[i].count(word)\n",
    "            # Only populate the matrix if non-zero to keep it sparse\n",
    "            if num_appearances != 0:\n",
    "                result[i, j] = num_appearances\n",
    "    return result\n",
    "\n",
    "ohm = one_hot_sentence_word_fit(X_tr)\n",
    "X_tr = one_hot_sentence_word_transform(X_tr, ohm)\n",
    "X_dev = one_hot_sentence_word_transform(X_dev, ohm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_predict_accuracy_lrm(X_tr, X_te, y_tr, y_te):\n",
    "    lrm = linear_model.LogisticRegression(penalty = 'l2')\n",
    "    lrm.fit(X_tr, y_tr)\n",
    "    return accuracy_score(lrm.predict(X_te), y_te)\n",
    "\n",
    "fit_predict_accuracy_lrm(X_tr, X_dev, y_tr, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.) word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* download the `GoogleNews-vectors-negative300.bin` file from https://github.com/mmihaltz/word2vec-GoogleNews-vectors and unzip the file\n",
    "* load the file by running the cell below (you may need to pip install gensim and you may need to change the path to the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models.word2vec import Word2Vec as w\n",
    "from gensim.models import KeyedVectors as kv\n",
    "w2v = kv.load_word2vec_format('/run/media/wd_blue_1000/word2vec/GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can access vectors like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09716797, -0.08496094,  0.27148438], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['red'][:3] # show the first three values for the vector for 'red'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* vectors are length 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v['red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the steps of preparing the test and dev data as in #4, only this time use w2v vectors\n",
    "* How to do you represent a tweet, which is multiple words, as a single vector? (Hint: try summing the vectors)\n",
    "* Note: w2v only has lower-cased words\n",
    "* Hint: if w2v doesn't have a word you are looking for, just ignore that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data by splitting on word\n",
    "X_tr = train.tweet.map(lambda x: x.split()).as_matrix()\n",
    "X_dev = dev.tweet.map(lambda x: x.split()).as_matrix()\n",
    "\n",
    "y_tr = train.polarity.as_matrix()\n",
    "y_dev = dev.polarity.as_matrix()\n",
    "\n",
    "def word_lists_to_w2v_vectors(X):\n",
    "    result = []\n",
    "    for x_cur in X:\n",
    "        cur_vec = [0.0 for i in range(300)]\n",
    "        for word in x_cur:\n",
    "            if word in w2v:\n",
    "                cur_vec += w2v[word]\n",
    "        result.append(cur_vec)\n",
    "    return np.matrix(result)\n",
    "\n",
    "X_tr = word_lists_to_w2v_vectors(X_tr)\n",
    "X_dev = word_lists_to_w2v_vectors(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_predict_accuracy_lrm(X_tr, X_dev, y_tr, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.) Comparing the three approaches\n",
    "\n",
    "* Now that you've tried things out on your `dev` set, train on your `train`+`dev` data and test on your `test` data for all three approaches and report the results. \n",
    "* Why do you think one-hot and word2vec worked better than the label encoder?\n",
    "* Did one-hot or word2vec work better? Why do you think that is the case?\n",
    "* What do you think would happen if you cleaned up the tweets (e.g., removed punctuation, emojis, etc.)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56375\n",
      "0.7375\n",
      "0.74625\n"
     ]
    }
   ],
   "source": [
    "# I don't quite understand the importance of the dev set. Your example code has training based on train,\n",
    "# then testing based on dev. Now we're just training with train+dev and testing with test. Aren't those\n",
    "# two things very similar?\n",
    "def get_new_clean_matrices(train, dev, test):\n",
    "    X_tr = train.tweet.map(lambda x: x.split()).as_matrix()\n",
    "    X_dev = dev.tweet.map(lambda x: x.split()).as_matrix()\n",
    "    X_te = test.tweet.map(lambda x: x.split()).as_matrix()\n",
    "\n",
    "    X_tr = np.concatenate((X_tr, X_dev))\n",
    "    X_dev = None\n",
    "\n",
    "    y_tr = train.polarity.as_matrix()\n",
    "    y_dev = dev.polarity.as_matrix()\n",
    "    y_te = test.polarity.as_matrix()\n",
    "\n",
    "    y_tr = np.concatenate((y_tr, y_dev))\n",
    "    y_dev = None    \n",
    "    return X_tr, X_te, y_tr, y_te\n",
    "\n",
    "# Label encoder\n",
    "X_tr, X_te, y_tr, y_te = get_new_clean_matrices(train, dev, test)\n",
    "\n",
    "lem = preprocessing.LabelEncoder()\n",
    "lem.fit(np.concatenate((X_tr, X_te)))\n",
    "X_tr = lem.transform(X_tr)\n",
    "X_tr = X_tr.reshape(X_tr.shape[0], 1)\n",
    "X_te = lem.transform(X_te)\n",
    "X_te = X_te.reshape(X_te.shape[0], 1)\n",
    "\n",
    "print(fit_predict_accuracy_lrm(X_tr, X_te, y_tr, y_te))\n",
    "\n",
    "# Word one-hot encoder\n",
    "X_tr, X_te, y_tr, y_te = get_new_clean_matrices(train, dev, test)\n",
    "\n",
    "ohm = one_hot_sentence_word_fit(X_tr)\n",
    "X_tr = one_hot_sentence_word_transform(X_tr, ohm)\n",
    "X_te = one_hot_sentence_word_transform(X_te, ohm)\n",
    "\n",
    "print(fit_predict_accuracy_lrm(X_tr, X_te, y_tr, y_te))\n",
    "\n",
    "# w2v encoder\n",
    "X_tr, X_te, y_tr, y_te = get_new_clean_matrices(train, dev, test)\n",
    "\n",
    "X_tr = word_lists_to_w2v_vectors(X_tr)\n",
    "X_te = word_lists_to_w2v_vectors(X_te)\n",
    "\n",
    "print(fit_predict_accuracy_lrm(X_tr, X_te, y_tr, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot and word2vec worked better because they preserved the semantic meaning of the sentence. By processing each word in the sentence, then putting them together in some way (in both cases, it was a sort of vector addition), we represent the sentence as a sum of words. Though we lose some information about the ordering of the words, this representation is more accurate than just using a label encoder. In addition, those representations do not have the \"arbitrary ordering\" problem of the label encoder. In the case of one-hot, we represent each word as a new, orthogonal unit vector in an ever increasing dimensionality. Thus, all words are equadistant from each other rather than, when using the label encoder, some sentences being closer to each other and other sentences being farther away from each other with no rhyme or reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot and w2v worked about the same (about 75% accuracy), which surprised me. I was expecting w2v to pull ahead of the one-hot encoder, because w2v is specially designed for this purpose. There could be several reasons for this. One reason is that tweets don't follow rigorous English standards, so you may end up with a word at the end of a sentence being, \"omg!!!!!!!\" which may not be present in that exact form in the w2v dictionary. In that case, my w2v code ignores that word and moves on. If tweets are composed of many of these abbreviations or words with weird punctuation, the sentence's representation could be pared down from, say, 12 words to a sum of a mere four or five vectors. Note that this problem is also present in the one-hot encoder, but only if we train the encoder on just the training data. If we were to train the one-hot encoder on train + test (potentially bad practice), we could capture all words in all tweets present in the data set, so each word would have a unique orthogonal vector (no information loss). One other potential reason that the w2v encoder didn't perform as well is that the w2v vectors are constrained to 300 dimensions. Though this may seem like a lot, it pales in comparison to the thousands of dimensions of the one-hot encoder. Though the w2v dictionary is specially designed for this purpose, this dimensionality could be limiting it from representing words as accurately as they could be represented. It could be that the developers made a tradeoff decision based on the size of the w2v data. The scope of the dictionary is huge, since it must basically cover every word of the English language. The dictionary is already ~3 GB, and adding more dimensions would just balloon that size even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tweets were cleaned up, both the one-hot and the w2v encoders would perform much better. They would encounter less words that are not in their respective dictionaries and thus ignore less of the input data. In addition, for the one-hot encoder, words like \"omg!!!!!\" and \"omg\" would no longer map to different one-hot values, so the model would treat those two words as the same (as it should, I think)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
